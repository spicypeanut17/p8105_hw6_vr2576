---
title: "P8105 Homework 6"
author: "Vaiju Raja (vr2576)"
date: "2024-12-02"
output: github_document
editor_options: 
  chunk_output_type: console
---


```{r lib}

library(tidyverse)
library(rvest)
library(broom)
library(rnoaa)
library(readr)
library(purrr)
library(modelr)
library(rsample)

```


## Problem 1: 2017 Central Park Weather Data

```{r q1, message = FALSE}

# Load data
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())


# Bootstrap sampling
set.seed(123) 

bootstrap_results <- weather_df %>%
  modelr::bootstrap(n = 5000) %>% # Generate 5000 bootstrap samples
  mutate(models = map(strap, ~lm(tmax ~ tmin, data = .x)), # Fit linear models
    rsq = map_dbl(models, ~broom::glance(.x)$r.squared), # Extract R^2
    log_beta_product = map_dbl(
      models, 
      ~{
        coefs <- broom::tidy(.x)
        log(coefs$estimate[1] * coefs$estimate[2])
      }
    )
  )

glimpse(bootstrap_results)


# Visualize the distributions
bootstrap_results %>%
  select(rsq, log_beta_product) %>%
  pivot_longer(cols = everything(), names_to = "metric", values_to = "value") %>%
  ggplot(aes(x = value)) +
  geom_density(aes(fill = metric), alpha = 0.5) +
  facet_wrap(~metric, scales = "free", labeller = as_labeller(
    c(rsq = "R-squared", log_beta_product = "Log(Beta_0 * Beta_1)")
  )) +
  theme_minimal() +
  labs(title = "Bootstrap Distributions",
    x = "Value",
    y = "Density")


# Calculate summary statistics
ci_results <- bootstrap_results %>%
  summarize(rsq_ci = list(quantile(rsq, probs = c(0.025, 0.975))),
    log_beta_ci = list(quantile(log_beta_product, probs = c(0.025, 0.975)))) %>%
  unnest_wider(c(rsq_ci, log_beta_ci), names_sep = "_")
ci_results

```


## Problem 2: Homicide Data Analysis

```{r q2, message = FALSE}

# Load and clean data
homicides_data = read_csv("data/homicide-data.csv") %>%
  filter(victim_race %in% c("White", "Black")) %>%
  mutate(victim_sex = factor(victim_sex, levels = c("Male", "Female")),  
        victim_sex = fct_drop(victim_sex),  # Drop the "Unknown" level
        victim_race = factor(victim_race, levels = c("White", "Black")),
    city_state = str_c(city, state, sep = ", "),
    resolved = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)) %>%
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) 

head(homicides_data)


## Baltimore data subset
baltimore_data = homicides_data %>%
  filter(city_state == "Baltimore, MD")

# Fit logistic regression model
baltimore_glm = glm(resolved ~ victim_age + victim_sex + victim_race, 
                    family = binomial(), 
                    data = baltimore_data)
baltimore_results = broom::tidy(baltimore_glm, exponentiate = TRUE, conf.int = TRUE)
baltimore_results

# Estimate and confidence interval for adjusted odds ratio for male vs. female
odds_ratio_baltimore = exp(baltimore_results %>% 
                           filter(term == "victim_sexFemale") %>% 
                           select(estimate, conf.low, conf.high))
odds_ratio_baltimore

baltimore_glm %>% 
  augment(type.predict = "response") %>% 
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residuals vs Fitted Values for Baltimore Model",
       x = "Fitted Values",
       y = "Residuals")


# Create cross-validation splits
cv_df = crossv_mc(baltimore_data, 100)

# Fit models and calculate RMSEs
cv_df = cv_df |>
  mutate(glm_mod = map(train, \(df) glm(resolved ~ victim_age + victim_race + victim_sex, 
                                   family = binomial(), data = df)),
    glm_mod_interaction = map(train, \(df) glm(resolved ~ victim_age + victim_race * victim_sex, 
                                               family = binomial(), data = df))) |>
  mutate(rmse_glm = map2_dbl(glm_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_glm_interaction = map2_dbl(glm_mod_interaction, test, \(mod, df) rmse(model = mod, data = df)))

# Visualize RMSE distributions
cv_df |>
  select(starts_with("rmse")) |>
  pivot_longer(everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |>
  mutate(model = fct_inorder(model)) |>
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()


## All cities
# Run logistic regression for each city and extract OR for sex
city_results = homicides_data %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(glm_model = map(data, ~ glm(resolved ~ victim_age + victim_sex + victim_race, 
                                     data = ., 
                                     family = binomial)),
         or_results = map(glm_model, ~ tidy(., exponentiate = TRUE, conf.int = TRUE) %>%
                           filter(str_detect(term, "victim_sexFemale")))) %>%
  unnest(or_results)
head(city_results)


# Plot the ORs with CIs for each city
city_results %>%
  ggplot(aes(x = city_state, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_pointrange(position = position_dodge(width = 0.7)) +
  coord_flip() +  
  labs(title = "Adjusted Odds Ratios for Male vs Female in Resolved Homicides",
    x = "City",
    y = "Odds Ratio (Female vs Male)") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 8))


```

**Baltimore:**
Female victims are 10.5 times more likely to have their homicides resolved than male victims. The confidence interval (6.01, 21.9) suggests that this result is statistically significant and points to a substantial gender disparity in homicide resolution rates.

Additionally, as the violin plots largely overlap, the models have similar predictive performance. 

**Adjusted Odds Ratios for Male vs Female in Resolved Homicides:**
Long Beach, CA, and New York, NY have the largest confidence intervals for the adjusted odds of resolved homicides by sex. This greater uncertainty in the estimate for these cities could be potentially due to higher data variability.

Indianapolis, IN, and Houston, TX are shown to have the smallest confidence intervals, suggesting that the estimates for these cities are more precise with less variability in the data.

Among the cities analyzed, New York, NY has the highest adjusted odds ratio (3.81) for resolved homicides by sex, meaning that women in New York City have a significantly higher likelihood of their homicides being solved compared to men. The confidence interval (2.06, 7.53) for New York also suggests that this result is statistically significant. 

In contrast, Albuquerque, NM has the lowest adjusted odds ratio (0.566), indicating that women in this city are much less likely to have their homicides solved compared to men. 



## Problem 3: Birthweight

```{r q3, message = FALSE, warning = FALSE}

# Load and clean data
birthweight_data = read_csv("data/birthweight.csv") %>%
  drop_na() %>%
  mutate(babysex = factor(babysex, levels = c("1", "2"), labels = c("Male", "Female")),
    frace = factor(frace, levels = c("1", "2", "3", "4", "8"), labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    mrace = factor(mrace, levels = c("1", "2", "3", "4"), labels = c("White", "Black", "Asian", "Puerto Rican")),
    malform = factor(malform, levels = c("0", "1"), labels = c("No", "Yes")))


## Fit a regression model and evaluate residuals
# My hypothesized model includes baby's sex (babysex), head circumference (bhead), length at birth (blength), motherâ€™s weight at delivery (delwt), family monthly income (fincome), gestational age in weeks (gaweeks), mother's height (mheight), mother's race (mrace), number of live births prior to this pregnancy (parity), and average number of cigarettes smoked per day during pregnancy (smoken). 
my_model = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + smoken, data = birthweight_data)

# Plot residuals vs fitted values
residuals_plot = birthweight_data %>% 
  add_residuals(my_model) %>%
  add_predictions(my_model) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values",
       y = "Residuals")
residuals_plot


# Fit comparison models
# Comparison Model 1: Length at birth (blength) and gestational age (gaweeks) as predictors (main effects only)
model1 = lm(bwt ~ blength + gaweeks, data = birthweight_data)

# Comparison Model 2: Head circumference (bhead), length at birth (blength), sex (babysex), and all interactions (including the three-way interaction) between these
model2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birthweight_data)

# Cross-validated prediction error
cv_df = crossv_mc(birthweight_data, 100)
cv_df = cv_df %>% 
  mutate(train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = cv_df %>% 
  mutate(my_mod  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + smoken, data = .x)),
    mod1  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    mod2  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_my = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
    rmse_1  = map2_dbl(mod1, test, ~rmse(model = .x, data = .y)),
    rmse_2  = map2_dbl(mod2, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()


``` 

**Model Predictors:**
Since we are dealing with birthweight, factors like maternal health (momage, ppbmi, ppwt, wtgain), baby health indicators (bhead, blength, gaweeks), and lifestyle factors (smoken, fincome) are reasonable predictors. However, the original model was complex with many predictors or interactions -- I had to simplify the model to include 

**Residuals vs Fitted Values Plot:**
The residuals plot suggests that the linear regression assumptions (linearity, homoscedasticity) are reasonably met as points are scattered randomly around the horizontal line at y = 0, there are no clear patterns or trends, and there is a relatively constant spread of residuals across fitted values.

**Cross-validated Prediction Error:**
My proposed model (my_mod) has the lowest median RMSE but has a wide distribution. This indicates that, on average, it provides the most accurate predictions of birthweight. However, the wide distribution of RMSE values indicates that its performance is somewhat inconsistent across different subsets of the data. 

Model1, which uses only length and gestational age as predictors, has a higher median RMSE, indicating lower overall predictive accuracy compared to my model. However, its narrow distribution suggests that it performs more consistently across different subsets of the data.

Model2, which includes interactions between head circumference, length, and sex, performs similarly to my proposed model. It has a slightly higher median RMSE but also exhibits a wide distribution of RMSE values. This suggests that the added complexity of the interactions doesn't substantially improve predictive performance over my model.
